import pandas as pd
import numpy as np
import string
import pip
import nltk
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import confusion_matrix, classification_report
#pip.main(['install','seaborn'])
import matplotlib.pyplot as plt
import seaborn as sns
#pip.main(['install','nltk'])

from nltk.corpus import stopwords
yelp = pd.read_csv('C:/Users/Shreyank/Desktop/Chirag Sir/yelp.csv')
yelp
yelp.shape
yelp.head()
yelp.info()
yelp.describe()
yelp['text length'] = yelp['text'].apply(len)
yelp.head()

g = sns.FacetGrid(data=yelp, col='stars')
g.map(plt.hist, 'text length', bins = 50)

sns.boxplot(x='stars', y='text length', data=yelp)
stars = yelp.groupby('stars').mean()
stars.corr()
sns.heatmap(data=stars.corr(), annot=True)
yelp_class = yelp[(yelp['stars'] == 1) | (yelp['stars'] == 5)]
yelp_class.shape
X = yelp_class['text']
y = yelp_class['stars']


def text_process(text):
    nopunc = [char for char in text if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
    
sample_text = "Hey there! This is a sample review, which happens to contain punctuations."
#nltk.download('stopwords')

print(text_process(sample_text))
bow_transformer = CountVectorizer(analyzer=text_process).fit(X)
len(bow_transformer.vocabulary_)
X = bow_transformer.transform(X)



density = (100.0 * X.nnz / (X.shape[0] * X.shape[1]))
density
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

nb = MultinomialNB()
nb.fit(X_train, y_train)
preds = nb.predict(X_test)
print(confusion_matrix(y_test, preds))
print('\n')
print(classification_report(y_test, preds))

nreview = yelp_class['text'][61]
nreview
nb.predict(bow_transformer.transform([nreview]))[0]